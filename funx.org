#+TITLE: A Functional Perspective on the NXP Architecture
#+SUBTITLE: Version {{{version}}}
#+AUTHOR: jmc
#+DATE: <2021-01-11 lun.>
#+OPTIONS: ':t toc:t author:t
#+LANGUAGE: en

#+MACRO: version 1.0

#+TEXINFO_FILENAME: funxp.info
#+TEXINFO_HEADER: @syncodeindex fn cp

#+TEXINFO_DIR_CATEGORY: NXP Architecture
#+TEXINFO_DIR_TITLE: funxp: (funxp)
#+TEXINFO_DIR_DESC: A Functional NXP Architecture

#+TEXINFO_PRINTED_TITLE: FUNXP

This manual is for FUNXP, a functional perspective on the NXP Architecture (version {{{version}}}).

* Introduction

Most of the ideas expressed in the historical series of computer programs, termed /NXP Architecture/ in this paper, were originally designed at the apex of one of the recurring cycle in the 30-year returns of the Artificial Intelligence (AI) debate, @@texinfo:@xref{JMC2018,,1}.@@ 

** A Dominant View, Symbolic Artificial Intelligence
#+CINDEX: Symbolic AI
Progressively in the late 70s and early 80s, the symbolic thread triumphed as the dominant paradigm of AI research. In 1984 for instance, at the climax of this cycle, early efforts to transfer research work to industrial applications were so introduced:

#+BEGIN_QUOTE
Artificial Intelligence is the subfield of computer science concerned with symbolic reasoning and problem-solving. [...] Knowledge Engineering is the process of incorporating symbolic knowledge into computer systems to solve problems normally requiring human attention and intelligence.[fn:1]
#+END_QUOTE 

#+CINDEX: Expert System
These computer systems incorporating symbolic knowledge became known as /Expert Systems/ and were all the rage, as industrial applications of AI, from the early eighties to the mid-nineties.

This somewhat restricted, to contemporary eyes, view of AI as a "subfield of computer science" geared towards augmenting traditional programs with symbolic knowledge was, however, perfectly in line with the precepts of the symbolic thread of AI research, established at the /Dartmouth Summer Research Project on Artificial Intelligence/ in 1956. Out of the variety of conceptual tenets of research on "thinking machines" in the 1950s, diversely known as /cybernetics/, /automata theory/ or /complex information processing/, stemmed out the original characteristics of the symbolic approach to AI: the importance of (mathematical) logic in high-level cognitive processes, and the prevalence of symbols in all aspects of cognition.

#+CINDEX: Physical Symbol System Hypothesis
The defining assumption, /the physical symbol system hypothesis/, is the philosophical perspective on AI assessed by Allen Newell and Herbert A. Simon:

#+BEGIN_QUOTE
A physical symbol system has the necessary and sufficient means for general intelligent action, @@texinfo:@xref{Newell1972,,3}.@@
#+END_QUOTE 

#+CINDEX: goal
#+CINDEX: working memory
#+CINDEX: computer/brain analogy
With symbols, structures come naturally as list of symbols and cognitive processes are understood as controlled by signal and symbol structures in /working memory/, i.e. arbitrary list structures in an extensive database-like system, called /goals/, @@texinfo:@xref{PDIS1978,,4}.@@ On the one hand, note the implicit analogy with the Turing machine model of a computer[fn:2], where perceptions are turned into symbols in memory, feeding a processor which elects further actions, operating changes in the environment. And, on the other hand, delineating further this analogy, the notions of symbols and lists from which LISP, and all its functional programming languages descendance in computer science, was derived, by the same contributors to the seminal Dartmouth workshop[fn:3].

#+CINDEX: CMU
While the seminal ideas for the NXP Architecture stemmed from a very early interest in what would be now termed /learning concepts/ (see [[How we got here]]), they were readily influenced and refined by the dominant view at the time, all the more so that they matured in the cultural environment of Carnegie-Mellon University (CMU), namely of its Computer Science and Robotics Institute departments, from 1982 to 1984.

** Production Systems and Rule-based Systems.


#+CAPTION: Model Human Processor in /The Psychology of Human-computer Interaction/, by Card, Newell, Moran (1983)
#+attr_texinfo: :width 200px :center t
[[./MODEL-HUMAN-PROCESSOR-w200.jpg]]


Productions and rules systems.

Medical consultation as a task environment.

* How we got here

A quick word on previous implementations. Interpreter v. compilers.

Emacs-Lisp.

~funxp~ is both a programming language and an interactive programming environment for expert systems. (Ref IPE1984.) It embeds NCLOSE, an earlier inference engine, in a simple -- even simplistic -- functional programming language called ~funx~ (/functional expressions/).

* A simplistic functional language, funx
#+CINDEX: funx
This section describes a simple functional programming language, ~funx~, evidently based on LISP with a minimal set of built-in functions. 

** Rehash of Henderson's book and other references of the 60s and 70s. Sexps.

** Simple subset of LISP. SECD Machine. Compiling funx to SECD assembly.

* An extension for NXP-style inferencing, funxp
#+CINDEX: funxp

Promises and delay/force. A mention of thread and parallelism (QLISP, Kugel non-halting computations v. thinking).

Data-driven vs. call: Hewitt mentioned in Sacerdoti as pattern-directed function invocation.

NXP-style rules. Rule: Hypo LHS &optional RHS &optional :context.

Glossary of terms: hypo(thesis), cond(itions), LHS/RHS, actions, sign, goal/subgoal, backward/forward chaining, knowcess, gating...

* Compiling funxp to SECD assembly

Knowledge base, or rule sets, are compiled to funxp environments.

Decorations and globales.

* An Emacs-based client

** Session. Interactivity. Trace and protocol.

** Encyclopedia and tree representation. Commands.
#+CINDEX: Encylopedia

#+ATTR_TEXINFO: :table-type vtable 
#+BEGIN_QUOTE
  - `q' :: Kill Encyclopedia buffer.
  - `k' :: Suggest hypo at point and knowcess.
  - `w' :: Volunteer, or What-if, data at point and knowcess.
  - `a' :: Answer pending question and resume session.
  - `r' :: Restart session.
  - `t' :: Open backward-chaining tree of hypo at point.
#+END_QUOTE

* Bibliography
Source: ~funx.bib~.

#+NAME: bibliography
#+BEGIN_SRC emacs-lisp :results value raw :exports results 
  (require 'parsebib)
  (require 'subr-x)

  (defun funx-parse (fname)
    (with-temp-buffer
      (insert-file-contents fname)
      (parsebib-collect-entries)))

  (defun funx-trim (str)
    (let ((re "[ \t\n\r\"{}]+"))
      (string-trim-left (string-trim-right str re) re)))

  (defun funx-first (keys alist)
    (if (null keys) ""
      (if (assoc (car keys) alist)
	  (cdr (assoc (car keys) alist))
	(funx-first (cdr keys) alist))))

  (let ((nref 0)
	(outstr "\n\n")
	(funx-bib (funx-parse "C:/Users/jmc/Documents/code/funx/funx.bib")))
    (maphash
     #'(lambda (key value)
	 (setq nref (1+ nref))
	 (setq outstr
	       (concat
		outstr
		(format
		 "@@texinfo:@anchor{%s}@@%d. %s. /%s/. %s, %s.\n\n"
		 key nref
		 (funx-trim (cdr (assoc "author" value)))
		 (funx-trim (cdr (assoc "title"  value)))
		 (funx-trim
		  (funx-first '("publisher" "journal" "institution") value))
		 (funx-trim (cdr (assoc "year"   value))))
		)))
     funx-bib)
     outstr)
#+END_SRC
* Test WIP                                                         :noexport:

From funx.bib

@@texinfo:@anchor{Rougier2005}@@ 1. Rougier, Nicolas P. and Noelle, David C. and Braver, Todd S. and Cohen, Jonathan D. and O{\textquoteright}Reilly, Randall C., Prefrontal cortex and flexible cognitive control: Rules without symbols, (2005) National Academy of Sciences

@@texinfo:@anchor{Newell1972}@@ 2. Newell, Allen and Simon, H. A., Human Problem Solving, (1972) Prentice-Hall, Inc.

@@texinfo:@anchor{PDIS1978}@@ 3. Waterman, D. A. and Hayes-Roth, Frederick, Pattern-Directed Inference Systems, (1978) Academic Press, Inc.

@@texinfo:@anchor{Post1943}@@ 4. Emil L. Post, Formal Reductions of the General Combinatorial Decision Problem, (1943) Association for Symbolic Logic

@@texinfo:@anchor{Markov1957}@@ 5. A. A. Markov, Theory of Algorithms, (1957) Association for Symbolic Logic

@@texinfo:@anchor{Floyd1961}@@ 6. Floyd, Robert W., An Algorithm for Coding Efficient Arithmetic Operations, (1961) Association for Computing Machinery

@@texinfo:@anchor{Chomsky57}@@ 7. Chomsky, Noam, Syntactic Structures, (1957) Mouton and Co.

@@texinfo:@anchor{Paycha1963}@@ 8. Paycha, F., Cybern{\'e}tique de la consultation: logique et morale de la m{\'e}decine, (1963) Gauthier-Villars

@@texinfo:@anchor{Rappaport-1984-15190}@@ 9. Alain Rappaport and Jean-Marie C. Chauvet, Symbolic Knowledge Processing for he Acquisition of Expert Behavior: A Study in Medicine, (1984) Carnegie Mellon University

@@texinfo:@anchor{Buchanan1984}@@ 10. Buchanan, Bruce G. and Shortliffe, Edward H., Rule Based Expert Systems: The Mycin Experiments of the Stanford Heuristic Programming Project (The Addison-Wesley Series in Artificial Intelligence), (1984) Addison-Wesley Longman Publishing Co., Inc.

@@texinfo:@anchor{Steele77}@@ 11. Guy L. Steele Jr., Debunking the "expensive procedure call" myth or, procedure call implementations considered harmful or, {LAMBDA:} The Ultimate {GOTO, (1977) ACM

@@texinfo:@anchor{Steele1976}@@ 12. Steele Jr., Guy Lewis and Sussman, Gerald Jay, LAMBDA: the ultimate imperative, (1976) 

@@texinfo:@anchor{Moses1970}@@ 13. Moses, Joel, The Function of FUNCTION in LISP or Why the FUNARG Problem Should Be Called the Environment Problem, (1970) Association for Computing Machinery

@@texinfo:@anchor{IPE1984}@@ 14. Barstow, David R. and Shrobe, Howard E. and Sandewall, Erik., Interactive programming environments / editors, David R. Barstow, Howard E. Shrobe, Erik Sandewall, (1984) McGraw-Hill New York

@@texinfo:@anchor{Appel1991}@@ 15. Appel, Andrew W., Compiling with Continuations, (1991) Cambridge University Press

@@texinfo:@anchor{Bundy1984}@@ 16. Bundy, Alan and Wallen, Lincoln, Lispkit, (1984) Springer Berlin Heidelberg

@@texinfo:@anchor{Henderson1976}@@ 17. Henderson, Peter and Morris, James H., A Lazy Evaluator, (1976) Association for Computing Machinery

@@texinfo:@anchor{Henderson1980a}@@ 18. P. Henderson, Functional Programming - Application and Implementation, (1980) Prentice-Hall Int. Series in Computer Science

@@texinfo:@anchor{Henderson1980b}@@ 19. Peter Henderson, Functional programming - application and implementation, (1980) Prentice Hall

@@texinfo:@anchor{Traub1991}@@ 20. Kenneth R. Traub, Implementation of non-strict functional programming languages, (1991) Pitman

@@texinfo:@anchor{FriedmanWise1976}@@ 21. Daniel P. Friedman and
               David S. Wise, CONS} Should Not Evaluate its Arguments, (1976) Edinburgh University Press

@@texinfo:@anchor{Keller1979}@@ 22. R. M. {KELLER} and G. {LINDSTROM} and S. {PATIL, A loosely-coupled applicative multi-processing system*, (1979) 1979 International Workshop on Managing Requirements Knowledge (MARK)

@@texinfo:@anchor{Turner1979}@@ 23. D. Turner, A new implementation technique for applicative languages, (1979) Software: Practice and Experience

@@texinfo:@anchor{Landin1964}@@ 24. Landin, P. J., The Mechanical Evaluation of Expressions, (1964) The Computer Journal

* Index
  :PROPERTIES:
  :INDEX:    cp
  :END:

* Footnotes

[fn:3]  In this context, progress in AI research was exemplified by  comprehensive descriptions of computer programs as landmark systems. @@texinfo:@xref{Feigenbaum1963,,5},@@ for such descriptions of the 1960s and 1950s systems. The import of the analogy between cognitive processes, in the human mind, and the workings of a computer program, was also felt in philosophy with the dramatic revival in the 1970s of /The Language of Thought/ hypothesis. The watershed was publication of Jerry Fodor's The Language of Thought (1975), triggering discussions and debates which continue to figure prominently within philosophy and cognitive science today. From a philosophical perspective, research programs such as "naturalizing intentionality" and "naturalizing consciousness" are still active although under a variety of cognitive assumptions, mirrorring the outpouring of results in neurosciences and computer science in the last decades.

[fn:2] The philosophical perspective so stated does not focus on /how/ the physical symbol system itself is actually realized. It obviously suggests that the human mind is such as system but also that, implicitly, physical symbol systems may be realised in Turing/Von Neumann computer architectures, and computer programs more specifically. And thus in the 1960s and 1970s it became an established practice to research theories about memory, reasoning or beliefs on computer programs as an experimental substrate, drawing conclusions deemed legitimate for cognition in the human mind. Contrast this to current Computational Neurosciences and to Connectionism's neural networks architectures, old and new.

[fn:1] Development of an expert system, /Daniel Sagalowicz/, Expert System, Vol. 1, Issue 2, Oct. 1984. 
